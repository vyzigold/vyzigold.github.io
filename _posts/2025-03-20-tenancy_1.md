---
title: Metric multi-tenancy with Prometheus part 1
categories:
- OpenStack
comments: true
feature_image: "https://vyzigold.github.io/placeholder.jpg"
---
The main telemetry signal we're able to collect in openstack are metrics. We have the ceilometer service, which is able to collect and export some openstack specific metrics, like CPU and memory consumption of each running VM. With Red Hat's RHOSO, you have access to other metrics as well, like NodeExporter metrics from your compute nodes, RabbitMQ metrics and so on.

After a metric is collected, it needs to be correctly transported and saved, so it can be viewed later. Openstack telemetry supports 2 backends for saving metrics. The first one is [Gnocchi]<https://github.com/gnocchixyz/gnocchi>. This is the original storage developed as part of openstack. It works pretty well and it's consistent with other openstack services. It has an openstack cli plugin and it correctly supports tenancy. The issue with Gnocchi is, that it doesn't scale very well. That's why we don't use it in RHOSO anymore. The second option is using Prometheus, which is de facto the leading metric storage outside of openstack. We're activelly working on improving our integration with Prometheus. The current issue with Prometheus is, that it doesn't know anything about OpenStack's tenancy model and it doesn't really support authentication (I think it's possible to configure basic auth, but that's it). This means, that everyone can see all the metrics.

I've been recently looking into solving the multi-tenancy and authentication issues with Prometheus and I have a potential solution. Ideally it'd need some more work, but what I'll describe should work nontheless. We'll need 2 additional components: Thanos, which will enforce tenancy and an authentication proxy, which will communicate with Keystone and it'll figure out for which project to query the metrics.

{% include figure.html image="/images/Thanos_multitenancy.drawio.png.jpg" caption="A scheme using Thanos for enforcing multitenancy" %}

But first we need to secure Prometheus so that it's not accessible to unprivileged users. The way I did that during my research is through having a network, which isn't accessible to users and configuring Prometheus to listen for queries only on that network. In my case I was working with RHOSO on kubernetes and I configured Prometheus to listen on localhost only. You can use the `--web.listen-address` parameter to do that or by specifying the `listenLocal: true` in the Prometheus CR when using the prometheus-operator on kubernetes.

Next you'll need to deploy [Thanos](https://thanos.io/). I deployed Thanos on RHOSO, so I won't go too much into details on how to deploy it elsewhere, for that refer to the [Thanos documentation](https://thanos.io/tip/thanos/getting-started.md/) . As part of RHOSO we currently have automatically deployed thanos sidecar in the Prometheus pod, which queries Prometheus's metrics through localhost, so it's still able to get the metrics even if Prometheus listens only on localhost. So all we need to do is to deploy a Thanos Querier, which will fetch the metrics from Prometheus through the Thanos Sidecar and it'll enforce required labels to enable tenancy. The communication between the Thanos Querier and Thanos Sidecar can be secured with mTLS, so that unprivileged users can't access the sidecar directly or through their own querier (This needs additional configuration. Automation is currently in development). The querier needs to be secured similarly to Prometheus, so that an unprivileged user can't access it and specify a project, to which the user shouldn't have any access. This can be done by specifying the `--http-address="127.0.0.1:10902"` argument.


Lastly, we need the authentication proxy, which will be placed between the user and the Thanos Querier. It'll listen to users requests, extract the users current project from Keystone and forward the request with the correct HTTP headers to Thanos. Unfortunatelly this part doesn't really exist at this point. There is just a [POC I've made](https://github.com/vyzigold/keystone-prometheus-proxy). Use at your own risk.

The Thanos Querier deployment together with the keystone proxy I used for my research looks like this:
```
apiVersion: apps/v1
kind: Deployment
metadata:
  name: thanos-querier-example-thanos
  namespace: openstack
spec:
  progressDeadlineSeconds: 300
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/instance: thanos-querier-example-thanos
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app.kubernetes.io/instance: thanos-querier-example-thanos
        app.kubernetes.io/managed-by: observability-operator
        app.kubernetes.io/part-of: ThanosQuerier
      name: thanos-querier-example-thanos
      namespace: openstack
    spec:
      containers:
      - name: proxy
        env:
        - name: PROMETHEUS_URL
          value: http://localhost:10902
        - name: KEYSTONE_URL
          value: https://keystone-internal:5000
        - name: PROXY_URL
          value: 0.0.0.0:9080
        image: quay.io/jwysogla/keystone-proxy-poc:latest
        imagePullPolicy: Always
        ports:
        - containerPort: 9080
          name: metrics-proxy
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
      - args:
        - query
        - --log.format=logfmt
        - --query.replica-label=prometheus_replica
        - --query.auto-downsampling
        - --query.tenant-header=X-Tenant
        - --query.tenant-label-name=project
        - --query.enforce-tenancy
        - --endpoint=dnssrv+_grpc._tcp.metric-storage-thanos-sidecar.openstack.svc.cluster.local
        - --http-address=localhost:10902
        image: registry.redhat.io/cluster-observability-operator/coo-thanos-rhel8@sha256:2dbd724e8c15a3e3ee809cb36ae1c481e27d1c492e0fe8d9dcce7971ba46a62f
        imagePullPolicy: IfNotPresent
        name: thanos-querier
        resources: {}
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          seccompProfile:
            type: RuntimeDefault
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: FallbackToLogsOnError
      dnsPolicy: ClusterFirst
      nodeSelector:
        kubernetes.io/os: linux
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      terminationGracePeriodSeconds: 30
```

This way, you can have a keystone authenticated enforced tenancy with metrics stored in Prometheus. This works with the new openstack metric cli plugin just like when using Prometheus directly when [this patch](https://github.com/vyzigold/observabilityclient/commit/9dd5ddae88c7fe3e67867f1749f09428e8d38535) is applied to it.
